{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42CRdtcCRTuc"
      },
      "source": [
        "# Assignment 1 – Polynomial Regression using ``torch.nn.Module``\n",
        "\n",
        "- Please create a copy of this notebook onto your own Drive before working on it: `File-->Save a copy in Drive`\n",
        "- Please submit your ipynb file named with your initials, e.g. `YGM-Assignment1.ipynb` with **the CODE cells output visible** to support your answers and **TEXTUAL answers given as comments** in the code cells.\n",
        "- Deadline for submission is **midnight, Friday, March 18th.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KvsIo2UfwO3"
      },
      "source": [
        "## Neural Network Model for Polynomial Regression\n",
        "Your task is to build a neural network for the function $y = x^2 + 3x$\n",
        "\n",
        "Requirements:\n",
        "- You MUST use `torch.nn.Module` to define your neural network class.\n",
        "- The training data should have **10 input values, $x$, and the correct corresponding output values, $y$,** for the function $y = x^2 + 3x$\n",
        "- The NN may have **maximum TWO hidden layers**.\n",
        "- You may use a **maximum of 500 neuron units in each hidden layer**.\n",
        "- You may train over a **maximum of 1000 epochs**.\n",
        "- Use suitable activation functions that have been covered in class.\n",
        "- You MUST use the **Adam optimiser, `torch.optim.Adam()`** and the **MSE loss function**.\n",
        "- **IMPORTANT:** Your model must have a **LOSS OF LESS THAN 0.01** at the end of training.\n",
        "- **Train your model at least 3 times** to see that the final loss value is stable across all three runs.\n",
        "- Print the loss at every 25th iteration.\n",
        "- Test the model on $x=10$.\n",
        "- **Save your training loss** at every iteration.\n",
        "\n",
        "Note:\n",
        "- If your model does not achieve a loss of less than 0.01, you will still be awarded marks for `Q7 – Q10` as long as you can explain your answers accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdiTwoHS93b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee69af73-44a3-415b-c83b-2c2038e62234"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Define training data for a the mathematical formula y = x^2 + 3x (3)\n",
        "\n",
        "x = torch.tensor([[-5],[-4],[-3],[-2],[-1],[0],[1],[2],[3],[4]],dtype = torch.float32)\n",
        "y = torch.tensor([[10],[4],[0],[-2],[-2],[0],[4],[10],[18],[28]],dtype = torch.float32)\n",
        "\n",
        "# 2. Define NN class (10)\n",
        "\n",
        "class MyNN(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.poly1 = nn.Linear(1, hidden_size)\n",
        "        self.poly2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.poly3 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.poly1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.poly2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.poly3(x)\n",
        "        return x\n",
        "\n",
        "# 3. Create an instance of NN model (2)\n",
        "hidden_size = 400\n",
        "model = MyNN(hidden_size)\n",
        "\n",
        "# 4. Loss and Optimiser (2)\n",
        "learning_rate = 0.01\n",
        "loss_fn = nn.MSELoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "# 5. Training loop\n",
        "# number of epochs need to be less than 1000\n",
        "num_epochs = 500\n",
        "training_loss = []\n",
        "epoch_ls = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # 5.1 Forward pass (2)\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "\n",
        "  # 5.2 Backward pass (3)\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "\n",
        "  # 5.3 Print loss every 25th epoch (1)\n",
        "  if (epoch + 1) % 25 == 0:\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss={loss.item():.4f} ')\n",
        "\n",
        "  # 5.4 Save training loss at every epoch (2)\n",
        "  training_loss.append(loss.item())\n",
        "  epoch_ls.append(epoch)\n",
        "\n",
        "# Ensure that loss is less than 0.01 at the end if training consistently (3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/500, Loss=4.2861 \n",
            "Epoch 50/500, Loss=0.3647 \n",
            "Epoch 75/500, Loss=0.1487 \n",
            "Epoch 100/500, Loss=0.0610 \n",
            "Epoch 125/500, Loss=0.0266 \n",
            "Epoch 150/500, Loss=0.0018 \n",
            "Epoch 175/500, Loss=0.0001 \n",
            "Epoch 200/500, Loss=0.0000 \n",
            "Epoch 225/500, Loss=0.0000 \n",
            "Epoch 250/500, Loss=0.0000 \n",
            "Epoch 275/500, Loss=0.0042 \n",
            "Epoch 300/500, Loss=0.0057 \n",
            "Epoch 325/500, Loss=0.0004 \n",
            "Epoch 350/500, Loss=0.0000 \n",
            "Epoch 375/500, Loss=0.0000 \n",
            "Epoch 400/500, Loss=0.0000 \n",
            "Epoch 425/500, Loss=0.0001 \n",
            "Epoch 450/500, Loss=0.0092 \n",
            "Epoch 475/500, Loss=0.0002 \n",
            "Epoch 500/500, Loss=0.0003 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Visualize (3)\n",
        "# Plot the landscape of your training loss (MSE loss) saved for every epoch.\n",
        "# y-axis would mean MSE loss and x-axis would mean the epoch of your training.\n",
        "# Hint: you should plot (1,first MSE loss), ... ,(last epoch number,last MSE loss)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title(\"Training Loss\")\n",
        "plt.plot(epoch_ls, training_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xXWhlxrmLBSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "38a54ed2-e8ac-402c-c439-143412a5f74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zatxfhYejeB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2466a54-26f6-468e-815e-03639b144fd2"
      },
      "source": [
        "# 7. Prediction (2)\n",
        "# Let's use the model on a new number x, defined as a tensor\n",
        "test_num = 40\n",
        "test = torch.tensor([test_num], dtype=torch.float32)\n",
        "\n",
        "# Get the model's prediction for this new x\n",
        "print(f'\\n\\nModel prediction for {test_num} is {model(test).item():.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Model prediction for 40 is 367.2011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmHgY1oDLiB"
      },
      "source": [
        "# Make sure the output of your code cells support your answers below:\n",
        "\n",
        "# Q8. Describe how the loss changed over time during training. (2)\n",
        "\n",
        "# The loss decreases over time during the training.\n",
        "\n",
        "# Q9. Is the prediction for x=10 close enough to the ideal value of 130?\n",
        "# Why do you think the prediction is or isn't close enough to the ideal value? (2)\n",
        "\n",
        "# The prediction is not close to the ideal value. This is probably due to the\n",
        "# training data. With the training data being so small in scale and very close\n",
        "# together x values, it does not fully depict the function for the model.\n",
        "\n",
        "# Q10. What are the predictions for x=20 and x=100? Based on these predictions,\n",
        "# comment on whether the model has captured the relationship between the training inputs and outputs. (2)\n",
        "\n",
        "# For x = 20, the predicted value was 179.7041 when the actual value is 460.\n",
        "# For x = 40, the predicted vlaue was 367.2011 when the actual value is 1720.\n",
        "# The model has not capture the relationship of the polynomial function\n",
        "# between the training input and the outputs.\n",
        "\n",
        "# Q11. Apart from tweaking the number of epochs and the number of neuron units in the hidden layer, think\n",
        "# of AT LEAST ONE more thing you would do to try to improve the model. You do NOT have to follow the\n",
        "# requirements nor to implement anything. (1)\n",
        "\n",
        "# I would provide much more training data. The dataset was too small to capture\n",
        "# the polynomial relationship.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}